{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39a3206c-6390-4a0b-923d-beb78a482eba",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "**KNN ML Supervised Algorithm for Suppplier Selection**\n\nThis notebook can be used by your Datascience team to run KNN clustering on prospective suppliers (operating on 10-12 features)"
  },
  {
   "cell_type": "code",
   "id": "f0d12194-bade-421a-a605-0513b3d59037",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "import streamlit as st\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import parallel_coordinates\nfrom sqlalchemy import create_engine\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\nengine = create_engine('sqlite://', echo=False)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d59d300d-ca89-439e-974e-c351d28aae5c",
   "metadata": {
    "language": "sql",
    "name": "cell5"
   },
   "outputs": [],
   "source": "--Prepopulate the supplier facts data directly from SNOWFLAKE\nselect supplier,quality,quantity,payment_method,serviceability,reputation,flexibility,financial_stability,supplier_assets,business_health,price,delivery_time,supplier_location_convenience from AUTOSCM.PUBLIC.SUPPLIERFACTS;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9110c494-d25e-4529-93bc-b60c23c0e31c",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": "#Write supplierfacts data to a dataframe\ndf = cell5.to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3d5bdecd-b507-4ebf-90a7-e72b1951fae5",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "#Scaling to the scale 0-10\n#Normalize the values across all the features being trained\ndf['DELIVERY_TIME'] = df['DELIVERY_TIME'] * 2\ndf['FLEXIBILITY'] = df['FLEXIBILITY'] * 2\ndf['PAYMENT_METHOD'] = df['PAYMENT_METHOD'] * 2\ndf['QUALITY'] = df['QUALITY'] * 2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d66190da-4dd3-489a-b381-6d88e23f1b51",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "#Drop Supplier Location convenience to avoid unintended bias to the ML feature training\ndf1 = df.drop([\"SUPPLIER_LOCATION_CONVENIENCE\"], axis =1)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "84567f9d-78d8-4ddb-82cb-68778eb5a39e",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "df2 = df1\n\nX = df2.drop(['SUPPLIER'], axis=1)\n\n#Normalize the features to a scale of 1 for k-value determination\n# Scale the features to have mean=0 and standard deviation=1, except for quantity and price\nscaler = StandardScaler()\nX_scaled = X.copy()\nX_scaled[X_scaled.columns.difference(['QUANTITY', 'PRICE'])] = scaler.fit_transform(X[X_scaled.columns.difference(['QUANTITY', 'PRICE'])])\n\n# Convert quantity to a rating on a scale of 0-10 (higher values are better)\nX_scaled['QUANTITY'] = (X_scaled['QUANTITY'] - X_scaled['QUANTITY'].min()) / (X_scaled['QUANTITY'].max() - X_scaled['QUANTITY'].min()) * 10\n\n# Perform k-means clustering with 2 clusters (ideal and not ideal)\nkmeans = KMeans(n_clusters=2, random_state=42)\ndf2['cluster'] = kmeans.fit_predict(X_scaled)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dfd143ee-85da-43ec-a0a3-5b8442fb9cb7",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "#print(df2[['SUPPLIER', 'cluster']])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3293d1fe-a162-42e2-9790-360df584080c",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": "from sklearn.preprocessing import MinMaxScaler\nfeatures = ['QUALITY', 'PAYMENT_METHOD', 'SERVICEABILITY',\n            'REPUTATION', 'FLEXIBILITY', 'FINANCIAL_STABILITY',\n            'SUPPLIER_ASSETS', 'BUSINESS_HEALTH', 'PRICE', 'DELIVERY_TIME']\n\n# Define equal feature weights for all parameters (sum of weights is 1)\nequal_weight = 1 / len(features)\nfeature_weights = {feature: equal_weight for feature in features}\n\n# Normalize the features using Min-Max scaling\nscaler = MinMaxScaler()\ndf_normalized = scaler.fit_transform(df[features])\n\n# Calculate the score for each supplier\ndf['score'] = (df_normalized * list(feature_weights.values())).sum(axis=1)\n\ndf_sorted = df.sort_values(by='score', ascending=False)\nprint(df_sorted[['SUPPLIER', 'score']])\n\nsupplier_grades = df_sorted.head(3)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a478c58e-5ad8-4556-8f19-09d487207dac",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "#Plot the Top 3 Suppliers\nax1 = supplier_grades.plot.scatter(x='SUPPLIER', y='score')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ad6a03dd-81c8-4b11-b409-c7f8a340cc5c",
   "metadata": {
    "name": "cell3",
    "collapsed": false
   },
   "source": "**To call this notebook as a function elsewhere**\n\n\n#execute notebook ML_Supplier_Selection_Algo ()"
  }
 ]
}